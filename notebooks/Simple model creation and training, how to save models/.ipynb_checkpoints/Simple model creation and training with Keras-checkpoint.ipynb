{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])\n",
    "# model.add(l4) Can also add layers like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, Dense is suggesting each layer, this is a 3 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 0.6932 - acc: 0.5995\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6725 - acc: 0.7452\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6480 - acc: 0.7986\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6188 - acc: 0.8290\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5851 - acc: 0.8324\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5453 - acc: 0.8452\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4986 - acc: 0.8433\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4415 - acc: 0.8771\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3839 - acc: 0.9110\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3490 - acc: 0.9205\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.3279 - acc: 0.9205\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.3135 - acc: 0.9243\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.3029 - acc: 0.9205\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2954 - acc: 0.9257\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2895 - acc: 0.9243\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2848 - acc: 0.9262\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2811 - acc: 0.9281\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2780 - acc: 0.9276\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2755 - acc: 0.9305\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2735 - acc: 0.9276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24982630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Epochs gives an accuracy of over 93% fit for the model. #notbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.2795 - acc: 0.9296 - val_loss: 0.1579 - val_acc: 0.9810\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.2783 - acc: 0.9360 - val_loss: 0.1556 - val_acc: 0.9762\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2773 - acc: 0.9302 - val_loss: 0.1546 - val_acc: 0.9810\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.2763 - acc: 0.9333 - val_loss: 0.1538 - val_acc: 0.9810\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.2757 - acc: 0.9328 - val_loss: 0.1513 - val_acc: 0.9810\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.2748 - acc: 0.9365 - val_loss: 0.1496 - val_acc: 0.9762\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2741 - acc: 0.9349 - val_loss: 0.1487 - val_acc: 0.9810\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2733 - acc: 0.9339 - val_loss: 0.1473 - val_acc: 0.9762\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2725 - acc: 0.9360 - val_loss: 0.1464 - val_acc: 0.9810\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2720 - acc: 0.9376 - val_loss: 0.1453 - val_acc: 0.9810\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2713 - acc: 0.9354 - val_loss: 0.1444 - val_acc: 0.9810\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2708 - acc: 0.9376 - val_loss: 0.1434 - val_acc: 0.9810\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2703 - acc: 0.9333 - val_loss: 0.1427 - val_acc: 0.9810\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2697 - acc: 0.9376 - val_loss: 0.1417 - val_acc: 0.9810\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2691 - acc: 0.9302 - val_loss: 0.1422 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2688 - acc: 0.9376 - val_loss: 0.1408 - val_acc: 0.9810\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2684 - acc: 0.9386 - val_loss: 0.1393 - val_acc: 0.9810\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2678 - acc: 0.9376 - val_loss: 0.1387 - val_acc: 0.9810\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2674 - acc: 0.9376 - val_loss: 0.1374 - val_acc: 0.9810\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2669 - acc: 0.9381 - val_loss: 0.1365 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c16bdd320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model is generalizing well on the validation data. Not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9735085 0.0264915]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.03740463 0.96259534]\n",
      "[0.97454816 0.02545181]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.68742335 0.31257668]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9769765  0.02302349]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.95284873 0.04715124]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.04828453 0.95171547]\n",
      "[0.97187114 0.02812889]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9209082  0.07909177]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9740334  0.02596659]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97242755 0.02757245]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.03740463 0.96259534]\n",
      "[0.95284873 0.04715124]\n",
      "[0.33972397 0.66027606]\n",
      "[0.9357315  0.06426853]\n",
      "[0.03150404 0.96849597]\n",
      "[0.51544213 0.48455787]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.96440625 0.03559376]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.96149606 0.03850393]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9765097  0.02349033]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9769765  0.02302349]\n",
      "[0.33972397 0.66027606]\n",
      "[0.9577705  0.04222945]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9740334  0.02596659]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.1475963 0.8524037]\n",
      "[0.9682966  0.03170344]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.9577705  0.04222945]\n",
      "[0.33972397 0.66027606]\n",
      "[0.68742335 0.31257668]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.1475963 0.8524037]\n",
      "[0.51544213 0.48455787]\n",
      "[0.17187223 0.82812774]\n",
      "[0.8936399  0.10636009]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97072536 0.02927465]\n",
      "[0.02043015 0.97956985]\n",
      "[0.9735085 0.0264915]\n",
      "[0.30025095 0.69974905]\n",
      "[0.6046658  0.39533418]\n",
      "[0.04435974 0.95564026]\n",
      "[0.9209082  0.07909177]\n",
      "[0.17187223 0.82812774]\n",
      "[0.8936399  0.10636009]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.3815565 0.6184435]\n",
      "[0.9262381  0.07376187]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02043015 0.97956985]\n",
      "[0.9701356  0.02986437]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.6046658  0.39533418]\n",
      "[0.09712493 0.90287507]\n",
      "[0.908297   0.09170299]\n",
      "[0.04074028 0.95925975]\n",
      "[0.97603357 0.02396642]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9695344  0.03046561]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.97454816 0.02545181]\n",
      "[0.02228711 0.97771287]\n",
      "[0.7913093 0.2086907]\n",
      "[0.17187223 0.82812774]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.03150404 0.96849597]\n",
      "[0.8604234  0.13957661]\n",
      "[0.01572294 0.98427707]\n",
      "[0.975053   0.02494699]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9765097  0.02349033]\n",
      "[0.02043015 0.97956985]\n",
      "[0.96710396 0.03289602]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9577705  0.04222945]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.97454816 0.02545181]\n",
      "[0.01572294 0.98427707]\n",
      "[0.975053   0.02494699]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9682966  0.03170344]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9209082  0.07909177]\n",
      "[0.04435974 0.95564026]\n",
      "[0.96297866 0.03702136]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9312357  0.06876432]\n",
      "[0.3815565 0.6184435]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.01319576 0.98680425]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9755481  0.02445191]\n",
      "[0.03150404 0.96849597]\n",
      "[0.8440517 0.1559483]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9312357  0.06876432]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.7913093 0.2086907]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.02228711 0.97771287]\n",
      "[0.9599345  0.04006553]\n",
      "[0.17187223 0.82812774]\n",
      "[0.9312357  0.06876432]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9577705  0.04222945]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.3815565 0.6184435]\n",
      "[0.68742335 0.31257668]\n",
      "[0.04435974 0.95564026]\n",
      "[0.9740334  0.02596659]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.97187114 0.02812889]\n",
      "[0.33972397 0.66027606]\n",
      "[0.6046658  0.39533418]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.01572294 0.98427707]\n",
      "[0.5605429 0.4394571]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.8936399  0.10636009]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9209082  0.07909177]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.9312357  0.06876432]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7250556  0.27494442]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.9689214  0.03107856]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97454816 0.02545181]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9357315  0.06426853]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.9434629 0.0565371]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9695344  0.03046561]\n",
      "[0.02228711 0.97771287]\n",
      "[0.96440625 0.03559376]\n",
      "[0.0733264 0.9266736]\n",
      "[0.9755481  0.02445191]\n",
      "[0.01319576 0.98680425]\n",
      "[0.96149606 0.03850393]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9262381  0.07376187]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.9469927  0.05300732]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.02043015 0.97956985]\n",
      "[0.97187114 0.02812889]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9735085 0.0264915]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.96578074 0.03421925]\n",
      "[0.02228711 0.97771287]\n",
      "[0.97603357 0.02396642]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.95018774 0.04981226]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.02228711 0.97771287]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02043015 0.97956985]\n",
      "[0.51544213 0.48455787]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9553743  0.04462571]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.97072536 0.02927465]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9469927  0.05300732]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9740334  0.02596659]\n",
      "[0.01440484 0.98559517]\n",
      "[0.8440517 0.1559483]\n",
      "[0.3815565 0.6184435]\n",
      "[0.9701356  0.02986437]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.6046658  0.39533418]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.9577705  0.04222945]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9599345  0.04006553]\n",
      "[0.01319576 0.98680425]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.96297866 0.03702136]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9701356  0.02986437]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.01319576 0.98680425]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9769765  0.02302349]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.09712493 0.90287507]\n",
      "[0.8936399  0.10636009]\n",
      "[0.01440484 0.98559517]\n",
      "[0.6046658  0.39533418]\n",
      "[0.04074028 0.95925975]\n",
      "[0.908297   0.09170299]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9735085 0.0264915]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9469927  0.05300732]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.97242755 0.02757245]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9357315  0.06426853]\n",
      "[0.33972397 0.66027606]\n",
      "[0.97603357 0.02396642]\n",
      "[0.17187223 0.82812774]\n",
      "[0.9469927  0.05300732]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9682966  0.03170344]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9262381  0.07376187]\n",
      "[0.33972397 0.66027606]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.51544213 0.48455787]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9695344  0.03046561]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.97242755 0.02757245]\n",
      "[0.19927402 0.800726  ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9357315  0.06426853]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.01440484 0.98559517]\n",
      "[0.975053   0.02494699]\n",
      "[0.03150404 0.96849597]\n",
      "[0.97454816 0.02545181]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.9765097  0.02349033]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.97130376 0.02869622]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7913093 0.2086907]\n",
      "[0.02228711 0.97771287]\n",
      "[0.96440625 0.03559376]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.7250556  0.27494442]\n",
      "[0.0733264 0.9266736]\n",
      "[0.51544213 0.48455787]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9735085 0.0264915]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.97603357 0.02396642]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9682966  0.03170344]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9209082  0.07909177]\n",
      "[0.02228711 0.97771287]\n",
      "[0.9765097  0.02349033]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9765097  0.02349033]\n",
      "[0.30025095 0.69974905]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9735085 0.0264915]\n",
      "[0.04435974 0.95564026]\n",
      "[0.7913093 0.2086907]\n",
      "[0.1475963 0.8524037]\n",
      "[0.68742335 0.31257668]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.0733264 0.9266736]\n",
      "[0.9262381  0.07376187]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9012102  0.09878978]\n",
      "[0.30025095 0.69974905]\n",
      "[0.51544213 0.48455787]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.3815565 0.6184435]\n",
      "[0.7250556  0.27494442]\n",
      "[0.03740463 0.96259534]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see these predictions with either a binary or a decimal without roundoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[194  16]\n",
      " [  9 201]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c179e9240>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices are a nice way to quickly see how our model is doing on data it hasn't seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('medical_trial_model.hS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The save function saves:\n",
    "\n",
    "### .  The architecture of the model\n",
    "### . The weights of the model\n",
    "### . The training configuration(loss, optimizer)\n",
    "### . The state of the optimizer, allowing to resume \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.hS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.29752684,  0.34815368,  0.5418557 ,  0.16172041,  0.59297836,\n",
       "         -0.17946382, -0.588934  ,  0.6267969 ,  0.6412854 , -0.16665101,\n",
       "         -0.33052388,  0.33428946,  0.45667672, -0.22736642,  0.71443874,\n",
       "         -0.20438784]], dtype=float32),\n",
       " array([ 0.03767541,  0.05522005, -0.16351368, -0.06905097, -0.15123987,\n",
       "         0.20370933, -0.00070344, -0.1154548 , -0.11855994,  0.19576623,\n",
       "         0.2518493 , -0.08337364, -0.15969774, -0.00052269, -0.1333591 ,\n",
       "        -0.00044735], dtype=float32),\n",
       " array([[ 0.13173893, -0.12501043,  0.09046026,  0.00098626,  0.00218084,\n",
       "          0.28181875,  0.14006796,  0.18413118,  0.0899009 , -0.39107174,\n",
       "          0.26479593,  0.37916607,  0.32014626,  0.00678432,  0.39790687,\n",
       "         -0.1974099 , -0.29930016, -0.17822976, -0.09805453, -0.17958902,\n",
       "          0.30773124,  0.08434781, -0.15390766,  0.37539545,  0.24493298,\n",
       "         -0.16513522, -0.21907291, -0.09416483,  0.32979363,  0.35635415,\n",
       "          0.17114127, -0.03586882],\n",
       "        [-0.12559672, -0.11731243,  0.02173798, -0.1956659 , -0.03737129,\n",
       "         -0.20690948,  0.0704753 ,  0.12307505,  0.18222904,  0.27732086,\n",
       "          0.21754768, -0.26187924,  0.02251782,  0.17535748, -0.0834879 ,\n",
       "          0.29303023, -0.12890263, -0.0921338 , -0.30402443,  0.03580057,\n",
       "          0.26479113, -0.11704434,  0.09857053, -0.07645903,  0.00742216,\n",
       "         -0.07198472,  0.31897557,  0.3918249 ,  0.07711922,  0.00701144,\n",
       "         -0.2379495 , -0.08290582],\n",
       "        [-0.15446688, -0.17010617, -0.04860795, -0.30577263, -0.24163747,\n",
       "          0.43244526, -0.13239096,  0.16504641, -0.13404393, -0.32541257,\n",
       "         -0.21598957, -0.37445715,  0.26797748,  0.08041041,  0.2597724 ,\n",
       "          0.10554319,  0.19942178,  0.19222604,  0.14994004, -0.18977025,\n",
       "         -0.24395062, -0.14847766, -0.21936795, -0.07487317,  0.3324221 ,\n",
       "         -0.04639676,  0.3808804 , -0.21720245,  0.10863151, -0.03838724,\n",
       "          0.06200004,  0.23320645],\n",
       "        [ 0.15798481, -0.3228865 , -0.22088961, -0.00150618,  0.03197446,\n",
       "          0.08779046, -0.11056558,  0.1685612 , -0.02310302, -0.21712953,\n",
       "         -0.02223715, -0.3731725 ,  0.28300053,  0.21568571,  0.09533703,\n",
       "         -0.08544824,  0.07421749,  0.18832175,  0.11153132,  0.3724006 ,\n",
       "         -0.32266572,  0.00704369, -0.11301728,  0.21807748,  0.11518735,\n",
       "         -0.01881715,  0.43805042,  0.05878392,  0.34578994, -0.3255935 ,\n",
       "         -0.14193125, -0.14386293],\n",
       "        [-0.1868069 ,  0.07871833, -0.29398772, -0.28303725, -0.14952856,\n",
       "          0.2004656 ,  0.03649061,  0.23748203,  0.03067465, -0.22568017,\n",
       "          0.19299541, -0.16283672,  0.41610628,  0.29637983,  0.2549138 ,\n",
       "         -0.12854244,  0.08621852, -0.17130801,  0.06835747,  0.22730792,\n",
       "         -0.33943582, -0.07054812, -0.40081018,  0.22710603,  0.43065023,\n",
       "         -0.05843133,  0.18222186, -0.35612813,  0.07142907, -0.10384964,\n",
       "         -0.31422597,  0.3067604 ],\n",
       "        [ 0.06243398, -0.12238748, -0.20981431,  0.00414749,  0.23911914,\n",
       "         -0.5949974 , -0.07357503, -0.5543731 , -0.6465787 ,  0.44016486,\n",
       "         -0.3643095 ,  0.39351347, -0.10050596, -0.36827224, -0.25084725,\n",
       "         -0.23825504,  0.08792496, -0.4886537 , -0.16406931, -0.00966857,\n",
       "          0.50543344, -0.02657068,  0.4863602 , -0.4476324 , -0.30996445,\n",
       "         -0.29229042, -0.28885448,  0.29553592, -0.3168566 ,  0.38590968,\n",
       "          0.49028853,  0.01387804],\n",
       "        [ 0.26410714,  0.06895141,  0.28868926,  0.2811841 ,  0.04755754,\n",
       "          0.17998789, -0.19785771,  0.08691388, -0.32335526,  0.17704822,\n",
       "         -0.12203804,  0.21336117, -0.32890978, -0.10674735, -0.33283988,\n",
       "         -0.27609622, -0.13535401, -0.1878158 ,  0.11892623, -0.27819204,\n",
       "         -0.20062087,  0.06255449, -0.060257  ,  0.2707133 , -0.340259  ,\n",
       "          0.09956305, -0.10463309, -0.28921998,  0.31609115,  0.24853162,\n",
       "         -0.2118717 ,  0.3502386 ],\n",
       "        [ 0.19764169, -0.14126888, -0.31809837,  0.28943574, -0.1015972 ,\n",
       "          0.19951217,  0.32135645,  0.27318177, -0.13301678, -0.01505356,\n",
       "          0.41099608,  0.10291129,  0.17429598,  0.2559458 ,  0.27373293,\n",
       "         -0.15391229, -0.34657753,  0.32603034, -0.08441269,  0.25387368,\n",
       "          0.05577246, -0.09394546, -0.32160428,  0.391109  ,  0.38086098,\n",
       "          0.06295254,  0.45731488,  0.11974736, -0.30179566, -0.4140494 ,\n",
       "         -0.3263706 ,  0.40950292],\n",
       "        [-0.2094595 ,  0.12027419, -0.02374489, -0.21471661, -0.06176275,\n",
       "          0.40621904,  0.38126326, -0.1741767 ,  0.37469748,  0.1709915 ,\n",
       "          0.2164396 ,  0.10965335,  0.28259853,  0.1486019 ,  0.1066125 ,\n",
       "         -0.15918623, -0.02242905,  0.3914282 , -0.13440543,  0.33954605,\n",
       "         -0.29273075, -0.20291857,  0.1305359 ,  0.01904522,  0.03278622,\n",
       "         -0.32568967,  0.3225912 , -0.1064521 , -0.30519184, -0.3764644 ,\n",
       "         -0.14494433,  0.12140533],\n",
       "        [ 0.5778131 ,  0.3896254 , -0.10777494, -0.2205261 ,  0.07404448,\n",
       "         -0.16050892, -0.346217  , -0.4194181 , -0.18152434,  0.6528426 ,\n",
       "         -0.11561096,  0.45862782, -0.35840365, -0.44489294, -0.5256526 ,\n",
       "         -0.01867138,  0.4031859 , -0.28661767, -0.11996649, -0.28891954,\n",
       "          0.41763118,  0.60987985,  0.16849044, -0.25353602, -0.23669365,\n",
       "          0.33804214, -0.44317415,  0.11914849, -0.24815518,  0.6313268 ,\n",
       "          0.5065576 , -0.4772263 ],\n",
       "        [ 0.6282764 ,  0.35722294, -0.32566705,  0.1892353 , -0.02311468,\n",
       "         -0.54637885, -0.56934893, -0.41477686, -0.4808614 ,  0.04007767,\n",
       "         -0.301367  ,  0.19103412, -0.20955414, -0.48032916, -0.745248  ,\n",
       "          0.07472456,  0.46763808, -0.4838755 , -0.29495013, -0.6812441 ,\n",
       "          0.5466519 ,  0.48129705,  0.02097278, -0.6477387 , -0.46817693,\n",
       "         -0.03859431, -0.38058406,  0.47660664, -0.34877658,  0.23297569,\n",
       "          0.08804218, -0.44206056],\n",
       "        [ 0.03025654, -0.15032487,  0.03387486,  0.15907694,  0.1725157 ,\n",
       "          0.49038988,  0.13887145,  0.1089737 ,  0.4649991 , -0.27031463,\n",
       "          0.42043588, -0.25272858,  0.14281444,  0.17915636,  0.32164377,\n",
       "         -0.23150857, -0.2308705 ,  0.2592988 , -0.10859592,  0.15515554,\n",
       "          0.08776936, -0.1191137 , -0.2611723 , -0.03401023,  0.13774137,\n",
       "         -0.31155562,  0.10269563,  0.01902411, -0.32614478, -0.23182672,\n",
       "          0.20836504,  0.36198395],\n",
       "        [ 0.03778448,  0.11679755,  0.09366298, -0.02351239, -0.24785446,\n",
       "          0.52428347,  0.06176264,  0.06283531,  0.09652704, -0.29366145,\n",
       "          0.22782744,  0.04982333,  0.00212621, -0.12194111, -0.00810961,\n",
       "         -0.04135831, -0.15375459,  0.3593576 , -0.2951783 ,  0.14313628,\n",
       "         -0.30729318, -0.05980133,  0.02569531, -0.20151457,  0.01909126,\n",
       "          0.11958428,  0.17025626, -0.32652608,  0.21587549,  0.21912079,\n",
       "         -0.3266433 , -0.07722178],\n",
       "        [ 0.24338302, -0.17293943, -0.25574225, -0.21716951, -0.07444149,\n",
       "          0.23020336,  0.34210494,  0.18286058,  0.15545925,  0.29841438,\n",
       "         -0.11002856,  0.22145376, -0.03297448,  0.32531497,  0.06159699,\n",
       "         -0.23387948,  0.1073052 , -0.06497177, -0.2898299 ,  0.32200238,\n",
       "         -0.16944635, -0.1846198 , -0.29420334, -0.04090422,  0.01151755,\n",
       "          0.13980249, -0.04458022, -0.22943136, -0.33347207, -0.04191989,\n",
       "          0.01359332,  0.0697729 ],\n",
       "        [ 0.06976189, -0.33221385, -0.25640726, -0.22378877, -0.03633438,\n",
       "         -0.04941564,  0.27489936,  0.452657  ,  0.41081688, -0.08971711,\n",
       "         -0.03041336, -0.38364565,  0.4037518 ,  0.32980078,  0.3175922 ,\n",
       "         -0.273189  ,  0.15732232,  0.27680436, -0.12869358,  0.25724363,\n",
       "         -0.23112847, -0.1679433 ,  0.11375486,  0.11362141,  0.295584  ,\n",
       "          0.00930357,  0.36049253, -0.32241082, -0.2901279 , -0.10471974,\n",
       "          0.1145769 ,  0.15311916],\n",
       "        [-0.10757182,  0.12265663, -0.28549975, -0.30005652,  0.18716088,\n",
       "         -0.1501138 , -0.2990097 ,  0.04005536, -0.11823057,  0.05102172,\n",
       "         -0.29778585, -0.2177371 , -0.04008076, -0.00303125, -0.2586967 ,\n",
       "          0.2138038 , -0.22673473, -0.0611769 , -0.03454828, -0.29344183,\n",
       "         -0.19957802,  0.24242294,  0.24764508,  0.1294916 ,  0.1991612 ,\n",
       "          0.24769595,  0.03616244,  0.3217232 ,  0.05120245, -0.17075816,\n",
       "          0.28116134,  0.31260413]], dtype=float32),\n",
       " array([ 0.09842785,  0.05098062, -0.00071648, -0.00071649,  0.15453987,\n",
       "        -0.09896394, -0.1066946 , -0.07671288, -0.07284456,  0.13616714,\n",
       "        -0.12783779,  0.1549564 , -0.13112476, -0.08900924, -0.08997965,\n",
       "        -0.00267562,  0.11034078, -0.03390304,  0.        , -0.06796475,\n",
       "         0.11851641,  0.19105688,  0.16717985, -0.01360862, -0.11963686,\n",
       "        -0.00229701, -0.1409863 ,  0.16171122, -0.00169459,  0.16756296,\n",
       "         0.1558162 , -0.08221563], dtype=float32),\n",
       " array([[ 0.3365343 , -0.49027625],\n",
       "        [-0.2688711 , -0.0214133 ],\n",
       "        [ 0.09622268,  0.37093443],\n",
       "        [-0.28992683,  0.00696016],\n",
       "        [ 0.69220805, -0.3419412 ],\n",
       "        [-0.10010897,  0.3120852 ],\n",
       "        [-0.28757682,  0.36465755],\n",
       "        [-0.38425514,  0.15940279],\n",
       "        [-0.45024157,  0.20726983],\n",
       "        [ 0.09541873, -0.44743717],\n",
       "        [-0.19589852,  0.5105615 ],\n",
       "        [ 0.30069253, -0.72699064],\n",
       "        [-0.04044233,  0.4209652 ],\n",
       "        [-0.10126114,  0.35882786],\n",
       "        [-0.42961222,  0.29878944],\n",
       "        [ 0.24886721,  0.3625871 ],\n",
       "        [ 0.14634846, -0.43903205],\n",
       "        [-0.49067286, -0.10910916],\n",
       "        [-0.13871762,  0.21405175],\n",
       "        [-0.46757072,  0.35108757],\n",
       "        [ 0.7343325 , -0.643691  ],\n",
       "        [ 0.1603193 , -0.7113656 ],\n",
       "        [ 0.60207844, -0.34368432],\n",
       "        [-0.45587185,  0.3926064 ],\n",
       "        [-0.48354182,  0.08594029],\n",
       "        [-0.41904387, -0.1932923 ],\n",
       "        [ 0.03931903,  0.3273774 ],\n",
       "        [ 0.65396136, -0.5244141 ],\n",
       "        [-0.08978979, -0.00911243],\n",
       "        [ 0.14795458, -0.47878015],\n",
       "        [ 0.47939268, -0.27620643],\n",
       "        [-0.26277423,  0.28629056]], dtype=float32),\n",
       " array([ 0.09591138, -0.09591138], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x1c17d61b70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. model.to_json()\n",
    "\n",
    "#### This is only saving the architecture of the model. No weights or training configuration will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as JSOW\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"theano\"}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model reconstruction from JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you only want the weights, you can save it as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.hS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('my_model_weights.hS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
