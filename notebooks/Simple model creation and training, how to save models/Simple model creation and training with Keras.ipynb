{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])\n",
    "# model.add(l4) Can also add layers like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, Dense is suggesting each layer, this is a 3 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 0.6932 - acc: 0.5995\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6725 - acc: 0.7452\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6480 - acc: 0.7986\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6188 - acc: 0.8290\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5851 - acc: 0.8324\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5453 - acc: 0.8452\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4986 - acc: 0.8433\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4415 - acc: 0.8771\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3839 - acc: 0.9110\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3490 - acc: 0.9205\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.3279 - acc: 0.9205\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.3135 - acc: 0.9243\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.3029 - acc: 0.9205\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2954 - acc: 0.9257\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2895 - acc: 0.9243\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2848 - acc: 0.9262\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2811 - acc: 0.9281\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2780 - acc: 0.9276\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2755 - acc: 0.9305\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2735 - acc: 0.9276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24982630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Epochs gives an accuracy of over 93% fit for the model. #notbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.2834 - acc: 0.9280 - val_loss: 0.1642 - val_acc: 0.9619\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.2825 - acc: 0.9222 - val_loss: 0.1615 - val_acc: 0.9857\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.2813 - acc: 0.9270 - val_loss: 0.1590 - val_acc: 0.9857\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2803 - acc: 0.9286 - val_loss: 0.1576 - val_acc: 0.9619\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.2796 - acc: 0.9249 - val_loss: 0.1550 - val_acc: 0.9857\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.2786 - acc: 0.9275 - val_loss: 0.1529 - val_acc: 0.9857\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2777 - acc: 0.9302 - val_loss: 0.1516 - val_acc: 0.9857\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2771 - acc: 0.9291 - val_loss: 0.1498 - val_acc: 0.9619\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2761 - acc: 0.9243 - val_loss: 0.1483 - val_acc: 0.9857\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2755 - acc: 0.9296 - val_loss: 0.1472 - val_acc: 0.9857\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2747 - acc: 0.9302 - val_loss: 0.1458 - val_acc: 0.9857\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2741 - acc: 0.9302 - val_loss: 0.1441 - val_acc: 0.9857\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2735 - acc: 0.9296 - val_loss: 0.1435 - val_acc: 0.9857\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2729 - acc: 0.9302 - val_loss: 0.1425 - val_acc: 0.9857\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2724 - acc: 0.9302 - val_loss: 0.1413 - val_acc: 0.9857\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2718 - acc: 0.9286 - val_loss: 0.1398 - val_acc: 0.9857\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2713 - acc: 0.9275 - val_loss: 0.1386 - val_acc: 0.9857\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2709 - acc: 0.9302 - val_loss: 0.1379 - val_acc: 0.9857\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2703 - acc: 0.9302 - val_loss: 0.1366 - val_acc: 0.9857\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2698 - acc: 0.9302 - val_loss: 0.1359 - val_acc: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111a3f080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model is generalizing well on the validation data. Not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77896875 0.22103123]\n",
      "[0.0463391 0.9536609]\n",
      "[0.77896875 0.22103123]\n",
      "[0.06325115 0.93674886]\n",
      "[0.9689727 0.0310273]\n",
      "[0.36498034 0.63501966]\n",
      "[0.88470554 0.11529446]\n",
      "[0.09472545 0.90527457]\n",
      "[0.9820538  0.01794618]\n",
      "[0.20131092 0.79868907]\n",
      "[0.9212252  0.07877481]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.6071525 0.3928475]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.97362655 0.02637342]\n",
      "[0.3276851 0.6723149]\n",
      "[0.96132535 0.03867467]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.9021839  0.09781612]\n",
      "[0.03699284 0.96300715]\n",
      "[0.96352834 0.03647165]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.8305303  0.16946971]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9153086  0.08469139]\n",
      "[0.13322896 0.86677104]\n",
      "[0.52638406 0.47361597]\n",
      "[0.03699284 0.96300715]\n",
      "[0.9021839  0.09781612]\n",
      "[0.04235755 0.95764244]\n",
      "[0.8941662  0.10583382]\n",
      "[0.10277015 0.89722985]\n",
      "[0.682456 0.317544]\n",
      "[0.06325115 0.93674886]\n",
      "[0.444211 0.555789]\n",
      "[0.07213856 0.92786145]\n",
      "[0.8524883  0.14751174]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.9267615  0.07323851]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.96543825 0.03456177]\n",
      "[0.03699284 0.96300715]\n",
      "[0.9089916  0.09100845]\n",
      "[0.07544883 0.9245512 ]\n",
      "[0.87144756 0.1285524 ]\n",
      "[0.05790469 0.94209534]\n",
      "[0.9212252  0.07877481]\n",
      "[0.1534435 0.8465565]\n",
      "[0.9865896  0.01341038]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.52638406 0.47361597]\n",
      "[0.0506751 0.9493249]\n",
      "[0.96543825 0.03456177]\n",
      "[0.11577859 0.88422143]\n",
      "[0.9865896  0.01341038]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.48519754 0.51480246]\n",
      "[0.03228469 0.9677153 ]\n",
      "[0.9089916  0.09100845]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.94128585 0.05871415]\n",
      "[0.07544883 0.9245512 ]\n",
      "[0.95620775 0.04379224]\n",
      "[0.05790469 0.94209534]\n",
      "[0.6071525 0.3928475]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9689727 0.0310273]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.5672148  0.43278524]\n",
      "[0.06325115 0.93674886]\n",
      "[0.9021839  0.09781612]\n",
      "[0.40397 0.59603]\n",
      "[0.96352834 0.03647165]\n",
      "[0.06325115 0.93674886]\n",
      "[0.52638406 0.47361597]\n",
      "[0.07213856 0.92786145]\n",
      "[0.9212252  0.07877481]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9860255  0.01397446]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9841892  0.01581077]\n",
      "[0.07213856 0.92786145]\n",
      "[0.87144756 0.1285524 ]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.8305303  0.16946971]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9494199  0.05058007]\n",
      "[0.0463391 0.9536609]\n",
      "[0.9089916  0.09100845]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.8305303  0.16946971]\n",
      "[0.06052269 0.9394773 ]\n",
      "[0.9820538  0.01794618]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.9763279 0.0236721]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.93193746 0.06806256]\n",
      "[0.0484611 0.9515389]\n",
      "[0.444211 0.555789]\n",
      "[0.2595329  0.74046713]\n",
      "[0.98543805 0.01456193]\n",
      "[0.09472545 0.90527457]\n",
      "[0.97362655 0.02637342]\n",
      "[0.03535435 0.9646456 ]\n",
      "[0.9803836  0.01961642]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.97502136 0.02497863]\n",
      "[0.07213856 0.92786145]\n",
      "[0.8305303  0.16946971]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.9803836  0.01961642]\n",
      "[0.36498034 0.63501966]\n",
      "[0.8305303  0.16946971]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.98543805 0.01456193]\n",
      "[0.11577859 0.88422143]\n",
      "[0.98543805 0.01456193]\n",
      "[0.06905501 0.930945  ]\n",
      "[0.9860255  0.01397446]\n",
      "[0.03228469 0.9677153 ]\n",
      "[0.8060473  0.19395266]\n",
      "[0.10277015 0.89722985]\n",
      "[0.96543825 0.03456177]\n",
      "[0.07544883 0.9245512 ]\n",
      "[0.8060473  0.19395266]\n",
      "[0.04235755 0.95764244]\n",
      "[0.48519754 0.51480246]\n",
      "[0.11577859 0.88422143]\n",
      "[0.6071525 0.3928475]\n",
      "[0.3276851 0.6723149]\n",
      "[0.9835259  0.01647414]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.8524883  0.14751174]\n",
      "[0.03870421 0.9612958 ]\n",
      "[0.9860255  0.01397446]\n",
      "[0.10277015 0.89722985]\n",
      "[0.7170637  0.28293628]\n",
      "[0.06325115 0.93674886]\n",
      "[0.87144756 0.1285524 ]\n",
      "[0.0506751 0.9493249]\n",
      "[0.9367726  0.06322742]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.97741735 0.02258267]\n",
      "[0.11577859 0.88422143]\n",
      "[0.9689727 0.0310273]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.98482627 0.01517371]\n",
      "[0.03535435 0.9646456 ]\n",
      "[0.8524883  0.14751174]\n",
      "[0.0506751 0.9493249]\n",
      "[0.97060615 0.02939383]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.9784577  0.02154229]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.88470554 0.11529446]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.9089916  0.09100845]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.98123693 0.01876308]\n",
      "[0.11577859 0.88422143]\n",
      "[0.98482627 0.01517371]\n",
      "[0.1534435 0.8465565]\n",
      "[0.97060615 0.02939383]\n",
      "[0.07544883 0.9245512 ]\n",
      "[0.95620775 0.04379224]\n",
      "[0.0463391 0.9536609]\n",
      "[0.8941662  0.10583382]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9860255  0.01397446]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.95307565 0.04692436]\n",
      "[0.07213856 0.92786145]\n",
      "[0.9494199  0.05058007]\n",
      "[0.1534435 0.8465565]\n",
      "[0.9267615  0.07323851]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.9865896  0.01341038]\n",
      "[0.03535435 0.9646456 ]\n",
      "[0.682456 0.317544]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.97741735 0.02258267]\n",
      "[0.09472545 0.90527457]\n",
      "[0.9153086  0.08469139]\n",
      "[0.3276851 0.6723149]\n",
      "[0.9212252  0.07877481]\n",
      "[0.03228469 0.9677153 ]\n",
      "[0.9454957 0.0545043]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.96543825 0.03456177]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.682456 0.317544]\n",
      "[0.1534435 0.8465565]\n",
      "[0.48519754 0.51480246]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9841892  0.01581077]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.6071525 0.3928475]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.9835259  0.01647414]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9835259  0.01647414]\n",
      "[0.03378589 0.9662141 ]\n",
      "[0.9367726  0.06322742]\n",
      "[0.04235755 0.95764244]\n",
      "[0.9784577  0.02154229]\n",
      "[0.40397 0.59603]\n",
      "[0.9860255  0.01397446]\n",
      "[0.07213856 0.92786145]\n",
      "[0.8524883  0.14751174]\n",
      "[0.07213856 0.92786145]\n",
      "[0.9267615  0.07323851]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.9267615  0.07323851]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.9835259  0.01647414]\n",
      "[0.0484611 0.9515389]\n",
      "[0.98123693 0.01876308]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.98123693 0.01876308]\n",
      "[0.3276851 0.6723149]\n",
      "[0.48519754 0.51480246]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.9803836  0.01961642]\n",
      "[0.2595329  0.74046713]\n",
      "[0.8305303  0.16946971]\n",
      "[0.06905501 0.930945  ]\n",
      "[0.87144756 0.1285524 ]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.6071525 0.3928475]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.9803836  0.01961642]\n",
      "[0.20131092 0.79868907]\n",
      "[0.97060615 0.02939383]\n",
      "[0.0484611 0.9515389]\n",
      "[0.8305303  0.16946971]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.5672148  0.43278524]\n",
      "[0.03870421 0.9612958 ]\n",
      "[0.682456 0.317544]\n",
      "[0.06325115 0.93674886]\n",
      "[0.444211 0.555789]\n",
      "[0.05790469 0.94209534]\n",
      "[0.98123693 0.01876308]\n",
      "[0.0463391 0.9536609]\n",
      "[0.96132535 0.03867467]\n",
      "[0.03378589 0.9662141 ]\n",
      "[0.95307565 0.04692436]\n",
      "[0.05790469 0.94209534]\n",
      "[0.9021839  0.09781612]\n",
      "[0.07213856 0.92786145]\n",
      "[0.9803836  0.01961642]\n",
      "[0.09472545 0.90527457]\n",
      "[0.9454957 0.0545043]\n",
      "[0.03870421 0.9612958 ]\n",
      "[0.9841892  0.01581077]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.97502136 0.02497863]\n",
      "[0.1534435 0.8465565]\n",
      "[0.682456 0.317544]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.97362655 0.02637342]\n",
      "[0.40397 0.59603]\n",
      "[0.9835259  0.01647414]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.9860255  0.01397446]\n",
      "[0.2595329  0.74046713]\n",
      "[0.9828352  0.01716486]\n",
      "[0.20131092 0.79868907]\n",
      "[0.9865896  0.01341038]\n",
      "[0.03699284 0.96300715]\n",
      "[0.52638406 0.47361597]\n",
      "[0.07544883 0.9245512 ]\n",
      "[0.93193746 0.06806256]\n",
      "[0.3276851 0.6723149]\n",
      "[0.9763279 0.0236721]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.8524883  0.14751174]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.52638406 0.47361597]\n",
      "[0.11577859 0.88422143]\n",
      "[0.9153086  0.08469139]\n",
      "[0.06052269 0.9394773 ]\n",
      "[0.7170637  0.28293628]\n",
      "[0.06905501 0.930945  ]\n",
      "[0.77896875 0.22103123]\n",
      "[0.36498034 0.63501966]\n",
      "[0.9828352  0.01716486]\n",
      "[0.03535435 0.9646456 ]\n",
      "[0.6457066 0.3542934]\n",
      "[0.0443057 0.9556943]\n",
      "[0.52638406 0.47361597]\n",
      "[0.22912487 0.7708751 ]\n",
      "[0.8305303  0.16946971]\n",
      "[0.0484611 0.9515389]\n",
      "[0.96352834 0.03647165]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.96352834 0.03647165]\n",
      "[0.0463391 0.9536609]\n",
      "[0.682456 0.317544]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.9021839  0.09781612]\n",
      "[0.09472545 0.90527457]\n",
      "[0.97060615 0.02939383]\n",
      "[0.11577859 0.88422143]\n",
      "[0.9153086  0.08469139]\n",
      "[0.20131092 0.79868907]\n",
      "[0.9021839  0.09781612]\n",
      "[0.03378589 0.9662141 ]\n",
      "[0.444211 0.555789]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9841892  0.01581077]\n",
      "[0.06905501 0.930945  ]\n",
      "[0.52638406 0.47361597]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.6457066 0.3542934]\n",
      "[0.03535435 0.9646456 ]\n",
      "[0.9828352  0.01716486]\n",
      "[0.06905501 0.930945  ]\n",
      "[0.97502136 0.02497863]\n",
      "[0.07213856 0.92786145]\n",
      "[0.98482627 0.01517371]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.9784577  0.02154229]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.9153086  0.08469139]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.8941662  0.10583382]\n",
      "[0.09472545 0.90527457]\n",
      "[0.8941662  0.10583382]\n",
      "[0.13322896 0.86677104]\n",
      "[0.96543825 0.03456177]\n",
      "[0.03228469 0.9677153 ]\n",
      "[0.8060473  0.19395266]\n",
      "[0.20131092 0.79868907]\n",
      "[0.93193746 0.06806256]\n",
      "[0.3276851 0.6723149]\n",
      "[0.6457066 0.3542934]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.5672148  0.43278524]\n",
      "[0.0484611 0.9515389]\n",
      "[0.9454957 0.0545043]\n",
      "[0.20131092 0.79868907]\n",
      "[0.9841892  0.01581077]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.9860255  0.01397446]\n",
      "[0.36498034 0.63501966]\n",
      "[0.444211 0.555789]\n",
      "[0.03084805 0.969152  ]\n",
      "[0.95307565 0.04692436]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9784577  0.02154229]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.52638406 0.47361597]\n",
      "[0.03699284 0.96300715]\n",
      "[0.9860255  0.01397446]\n",
      "[0.09472545 0.90527457]\n",
      "[0.9803836  0.01961642]\n",
      "[0.40397 0.59603]\n",
      "[0.444211 0.555789]\n",
      "[0.04235755 0.95764244]\n",
      "[0.9689727 0.0310273]\n",
      "[0.36498034 0.63501966]\n",
      "[0.9267615  0.07323851]\n",
      "[0.04049143 0.9595086 ]\n",
      "[0.9588426  0.04115741]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9454957 0.0545043]\n",
      "[0.05539326 0.9446067 ]\n",
      "[0.9763279 0.0236721]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9089916  0.09100845]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.9494199  0.05058007]\n",
      "[0.13322896 0.86677104]\n",
      "[0.8060473  0.19395266]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.9784577  0.02154229]\n",
      "[0.1534435 0.8465565]\n",
      "[0.94128585 0.05871415]\n",
      "[0.08753887 0.9124611 ]\n",
      "[0.9153086  0.08469139]\n",
      "[0.08084884 0.9191512 ]\n",
      "[0.48519754 0.51480246]\n",
      "[0.10277015 0.89722985]\n",
      "[0.9267615  0.07323851]\n",
      "[0.3276851 0.6723149]\n",
      "[0.9153086  0.08469139]\n",
      "[0.06052269 0.9394773 ]\n",
      "[0.74928546 0.25071454]\n",
      "[0.2595329  0.74046713]\n",
      "[0.52638406 0.47361597]\n",
      "[0.04235755 0.95764244]\n",
      "[0.9089916  0.09100845]\n",
      "[0.06325115 0.93674886]\n",
      "[0.9860255  0.01397446]\n",
      "[0.10277015 0.89722985]\n",
      "[0.9784577  0.02154229]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.5672148  0.43278524]\n",
      "[0.3276851 0.6723149]\n",
      "[0.97362655 0.02637342]\n",
      "[0.0443057 0.9556943]\n",
      "[0.9820538  0.01794618]\n",
      "[0.09472545 0.90527457]\n",
      "[0.9588426  0.04115741]\n",
      "[0.06609391 0.9339061 ]\n",
      "[0.74928546 0.25071454]\n",
      "[0.36498034 0.63501966]\n",
      "[0.93193746 0.06806256]\n",
      "[0.0506751 0.9493249]\n",
      "[0.93193746 0.06806256]\n",
      "[0.05298462 0.9470154 ]\n",
      "[0.96352834 0.03647165]\n",
      "[0.17610212 0.8238979 ]\n",
      "[0.9267615  0.07323851]\n",
      "[0.29244557 0.7075544 ]\n",
      "[0.9803836  0.01961642]\n",
      "[0.05790469 0.94209534]\n",
      "[0.96132535 0.03867467]\n",
      "[0.03228469 0.9677153 ]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see these predictions with either a binary or a decimal without roundoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[189  21]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c25e5ecf8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices are a nice way to quickly see how our model is doing on data it hasn't seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('medical_trial_model.hS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The save function saves:\n",
    "\n",
    "### .  The architecture of the model\n",
    "### . The weights of the model\n",
    "### . The training configuration(loss, optimizer)\n",
    "### . The state of the optimizer, allowing to resume \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.hS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.3344439 ,  0.32749036,  0.26193646, -0.28967062, -0.4204343 ,\n",
       "         -0.432962  , -0.3455889 ,  0.2620321 , -0.3514745 , -0.10505974,\n",
       "          0.3349751 , -0.39217865,  0.4146039 , -0.2246217 , -0.18670923,\n",
       "          0.5052649 ]], dtype=float32),\n",
       " array([-0.00051256, -0.02262442, -0.02797438, -0.00051285, -0.00051259,\n",
       "        -0.00051286,  0.26429725,  0.09801745,  0.26943305, -0.00051263,\n",
       "        -0.0825032 , -0.00051277, -0.1165777 ,  0.17340027, -0.00027966,\n",
       "        -0.07604203], dtype=float32),\n",
       " array([[ 1.53025836e-01, -1.48926944e-01,  5.24124205e-02,\n",
       "          3.33151132e-01, -2.73185015e-01, -8.11090469e-02,\n",
       "         -2.47800738e-01,  2.28123039e-01, -2.68269718e-01,\n",
       "         -3.13172638e-02,  2.68065602e-01, -1.39232725e-01,\n",
       "         -8.09081197e-02, -8.80455971e-02, -9.90383625e-02,\n",
       "          1.77702695e-01, -2.47203290e-01,  9.60749090e-02,\n",
       "         -2.22597733e-01, -7.68622458e-02, -7.31464326e-02,\n",
       "         -2.69325376e-02,  2.79128879e-01, -1.23029202e-01,\n",
       "          1.47122145e-03, -2.71853805e-02,  1.72645777e-01,\n",
       "          2.85067469e-01, -3.08786362e-01,  3.03013414e-01,\n",
       "          1.03800863e-01,  3.15838009e-01],\n",
       "        [-2.21140310e-01, -8.14321712e-02,  2.69553542e-01,\n",
       "         -1.01928204e-01,  7.13879243e-02,  1.77217111e-01,\n",
       "         -3.03144485e-01,  8.33938345e-02, -3.11978012e-01,\n",
       "          7.61875063e-02, -3.68355483e-01, -3.24942291e-01,\n",
       "          5.28150737e-01,  2.47230213e-02,  1.09693438e-01,\n",
       "         -3.53592783e-01,  1.27117813e-01,  1.30869061e-01,\n",
       "         -4.42416936e-01,  9.89531055e-02,  3.83591168e-02,\n",
       "         -3.02944660e-01,  3.91332686e-01, -1.03829920e-01,\n",
       "          1.22311741e-01, -9.78132710e-02, -2.25284904e-01,\n",
       "         -7.82966837e-02, -1.06263183e-01, -8.97049010e-02,\n",
       "          3.47859830e-01, -1.06686570e-01],\n",
       "        [-3.45437303e-02, -2.42079392e-01,  4.85397190e-01,\n",
       "          1.40563488e-01,  4.12501544e-01, -4.93703857e-02,\n",
       "         -2.69795984e-01,  2.05421939e-01, -3.07134539e-01,\n",
       "         -1.91897810e-01,  4.01618294e-02, -2.95186549e-01,\n",
       "         -9.55297127e-02,  4.99563180e-02,  7.14562461e-02,\n",
       "          2.27551028e-01, -3.60644341e-01, -2.26823986e-01,\n",
       "         -8.91112611e-02,  1.98332697e-01,  3.40069681e-01,\n",
       "          2.92075783e-01,  5.39715528e-01,  5.36305197e-02,\n",
       "          3.25967580e-01,  1.54603019e-01,  1.56704038e-01,\n",
       "         -1.37312725e-01,  2.11940572e-01, -2.77178705e-01,\n",
       "          3.29958409e-01,  2.93266088e-01],\n",
       "        [-1.14964828e-01,  8.55538547e-02,  7.29840994e-03,\n",
       "          3.27860028e-01, -1.18114248e-01, -1.18734390e-01,\n",
       "         -3.38651419e-01, -5.92257380e-02,  5.49802184e-03,\n",
       "          2.39020735e-01, -2.27973342e-01,  2.20388204e-01,\n",
       "         -8.72766078e-02, -2.65105963e-01,  2.52790004e-01,\n",
       "          7.41552711e-02, -2.24166393e-01,  1.26090080e-01,\n",
       "          1.96991652e-01, -2.84543663e-01,  3.51685613e-01,\n",
       "         -1.92669556e-01,  1.01293087e-01, -3.46249342e-03,\n",
       "          2.52204686e-01, -2.06672445e-01, -4.46566939e-03,\n",
       "          3.41134071e-02,  2.31190324e-02, -9.42240059e-02,\n",
       "          1.49009317e-01,  2.54415005e-01],\n",
       "        [ 8.98892879e-02,  7.66731799e-02,  2.66407639e-01,\n",
       "         -1.90333560e-01, -1.51483878e-01,  1.30988955e-02,\n",
       "          1.71135873e-01, -1.10438854e-01,  1.11337692e-01,\n",
       "         -5.44288754e-02,  1.53802335e-02, -1.76165104e-02,\n",
       "          2.33983010e-01,  2.93538839e-01,  1.20153129e-02,\n",
       "          3.50694507e-01, -2.83889771e-02, -1.94918394e-01,\n",
       "         -4.22464311e-02, -2.87591219e-01, -2.37667650e-01,\n",
       "         -1.11452341e-02, -1.26125768e-01,  2.31960088e-01,\n",
       "          3.09532493e-01,  1.50635839e-02, -3.35281312e-01,\n",
       "         -1.93537191e-01,  1.75963670e-01,  3.09704036e-01,\n",
       "         -1.45820975e-02, -2.63642520e-01],\n",
       "        [ 2.46358186e-01, -9.99673903e-02,  3.40439886e-01,\n",
       "          3.15979868e-01, -2.68339992e-01, -2.72771746e-01,\n",
       "          3.38361353e-01,  2.85769135e-01, -3.52125853e-01,\n",
       "          1.92466348e-01,  3.46195787e-01, -3.41302186e-01,\n",
       "         -2.42177814e-01,  3.66744101e-02, -1.74677670e-01,\n",
       "          3.01031858e-01,  2.25224346e-01,  1.68177873e-01,\n",
       "         -1.81464940e-01,  1.70464724e-01, -2.19787136e-01,\n",
       "          1.90337509e-01, -2.34141350e-01,  1.91786021e-01,\n",
       "         -2.15392008e-01,  1.77055806e-01,  1.48940355e-01,\n",
       "          5.91827333e-02, -1.71839908e-01, -3.49970162e-01,\n",
       "         -1.25162005e-02,  2.13617653e-01],\n",
       "        [ 6.29935145e-01,  2.92141050e-01, -8.13689053e-01,\n",
       "         -2.62414485e-01, -2.66933888e-01,  4.56307918e-01,\n",
       "         -1.64651796e-01, -6.05213940e-01,  6.92618251e-01,\n",
       "          3.42202932e-01,  3.97473663e-01, -2.46122450e-01,\n",
       "         -5.27108848e-01,  6.33211136e-01,  1.89179122e-01,\n",
       "         -1.86311781e-01,  3.51091683e-01, -1.62547916e-01,\n",
       "          6.19453251e-01, -7.50702322e-01, -1.47065341e-01,\n",
       "          2.33717352e-01, -7.73947239e-01,  5.40993989e-01,\n",
       "          8.40696990e-02,  6.69742823e-01, -1.27234563e-01,\n",
       "          1.19256340e-01, -2.42564783e-01, -3.25236917e-01,\n",
       "         -3.39030147e-01, -4.45600688e-01],\n",
       "        [ 2.17022493e-01, -9.75963771e-02,  8.54781717e-02,\n",
       "         -2.07797587e-02,  2.73853093e-01,  2.32593879e-01,\n",
       "          1.23426974e-01,  2.01859355e-01,  1.57298207e-01,\n",
       "         -1.51550859e-01, -1.98249929e-02, -2.28004437e-02,\n",
       "          4.81432557e-01,  7.02884123e-02,  1.53777808e-01,\n",
       "         -3.28859664e-03,  3.02964687e-01, -3.09564948e-01,\n",
       "          2.50550717e-01,  3.20740193e-01,  3.07015870e-02,\n",
       "         -1.94446445e-02,  3.84140819e-01,  2.12145478e-01,\n",
       "         -1.16784915e-01,  3.46656404e-02, -8.87943804e-02,\n",
       "          1.38418242e-01,  1.15044601e-01,  1.86868489e-01,\n",
       "         -2.61719167e-01,  2.58064896e-01],\n",
       "        [ 6.45989627e-02,  5.25648177e-01, -1.33237123e-01,\n",
       "          1.58943266e-01, -7.68583894e-01,  4.47783291e-01,\n",
       "          4.32814062e-02, -7.66426623e-01,  3.85985464e-01,\n",
       "          1.26995906e-01,  6.29524827e-01,  1.36934116e-01,\n",
       "         -6.31371498e-01,  5.40512621e-01,  4.11423855e-03,\n",
       "          5.83768487e-02,  4.13486242e-01, -1.45281658e-01,\n",
       "          6.39775872e-01, -4.08529758e-01, -5.27368248e-01,\n",
       "         -3.47116321e-01, -6.67253077e-01,  4.47859138e-01,\n",
       "         -1.81198880e-01,  4.50638771e-01, -8.66470039e-02,\n",
       "          4.11116719e-01, -6.67208850e-01,  2.15825647e-01,\n",
       "         -3.05656523e-01, -8.19167137e-01],\n",
       "        [ 7.49619603e-02,  1.08142495e-01, -2.34225363e-01,\n",
       "         -2.71302640e-01,  2.01337785e-01,  4.59018350e-03,\n",
       "          3.22593153e-02,  1.89268202e-01,  2.72537470e-02,\n",
       "         -9.09542441e-02,  1.95690066e-01,  2.91709334e-01,\n",
       "          2.85404295e-01,  1.52175039e-01,  2.54402727e-01,\n",
       "          1.90962583e-01,  7.74074793e-02, -8.88468921e-02,\n",
       "          1.12807989e-01,  1.10612661e-01,  1.15819365e-01,\n",
       "          2.97970563e-01,  1.94134086e-01, -3.93539667e-04,\n",
       "         -2.05136955e-01,  1.67366892e-01, -1.82265118e-01,\n",
       "         -2.21144453e-01, -1.93122029e-02, -7.01513290e-02,\n",
       "          1.93535358e-01,  4.08692360e-02],\n",
       "        [ 3.45491916e-02, -2.50049889e-01,  5.55938363e-01,\n",
       "         -6.20686412e-02,  2.61529595e-01, -2.70631760e-01,\n",
       "         -1.82476878e-01,  1.84664160e-01, -2.02559739e-01,\n",
       "         -8.23170096e-02, -3.02147388e-01,  1.43550932e-01,\n",
       "          2.55992919e-01, -2.16302853e-02,  8.46587494e-02,\n",
       "         -1.58705890e-01, -4.03863102e-01,  3.50872725e-01,\n",
       "         -3.86939883e-01,  3.92424375e-01,  3.21534097e-01,\n",
       "         -2.36574695e-01,  1.01303600e-01, -2.33509049e-01,\n",
       "         -1.91878438e-01, -1.08575709e-01, -5.51076829e-02,\n",
       "         -4.18329567e-01,  2.18523607e-01,  2.55786568e-01,\n",
       "          1.38133526e-01,  3.94744158e-01],\n",
       "        [-2.16886491e-01, -9.51777101e-02,  3.51788968e-01,\n",
       "          7.32436478e-02,  1.28482431e-01, -3.84838581e-02,\n",
       "         -2.90951610e-01,  3.50022018e-02, -2.14721620e-01,\n",
       "         -1.88289329e-01, -8.39945674e-02, -2.06915379e-01,\n",
       "         -4.58359718e-02,  2.03390628e-01, -3.33399057e-01,\n",
       "          1.14508718e-01, -5.16658723e-02, -2.63702452e-01,\n",
       "          1.67697668e-03,  2.32069224e-01,  2.67162770e-01,\n",
       "         -1.76715747e-01,  2.93973595e-01,  5.10209799e-02,\n",
       "         -2.05056995e-01,  1.37846798e-01, -2.94533700e-01,\n",
       "         -3.37081671e-01,  3.51610690e-01, -1.31160021e-03,\n",
       "          1.81117654e-03,  3.09360951e-01],\n",
       "        [-4.05254930e-01,  1.27121583e-01,  3.25357288e-01,\n",
       "         -3.89728844e-02,  1.80755109e-01, -4.93339747e-01,\n",
       "         -2.39890069e-01,  8.59924331e-02, -2.87946820e-01,\n",
       "         -8.77697915e-02,  1.08824573e-01, -1.38213322e-01,\n",
       "          4.95331019e-01, -1.31150201e-01, -3.54227215e-01,\n",
       "          1.54633239e-01, -3.26257318e-01, -3.24800342e-01,\n",
       "         -2.87199616e-01,  3.09158951e-01,  3.64477932e-01,\n",
       "         -1.68690309e-01,  6.57074898e-02, -4.86027598e-01,\n",
       "          4.37222123e-02, -4.35395926e-01,  1.20711952e-01,\n",
       "         -5.19694030e-01,  3.34190577e-01, -2.78956443e-01,\n",
       "         -9.65563357e-02,  4.01642054e-01],\n",
       "        [ 2.58097053e-01, -4.12168354e-02, -6.28343642e-01,\n",
       "         -3.42879504e-01, -4.72919077e-01,  5.43039501e-01,\n",
       "         -3.78587544e-02, -9.08382088e-02,  6.44641280e-01,\n",
       "          4.79519576e-01,  5.37556529e-01,  1.91483900e-01,\n",
       "         -5.09349167e-01,  2.65080184e-01, -2.57069886e-01,\n",
       "         -8.38795602e-02,  5.56036472e-01,  4.10508215e-02,\n",
       "          3.86932403e-01, -5.59037924e-01, -5.57916939e-01,\n",
       "         -3.25172544e-02, -2.64706582e-01,  5.45532167e-01,\n",
       "         -2.87775099e-01,  3.12679768e-01,  9.88265574e-02,\n",
       "          2.85107225e-01, -6.67931259e-01, -1.11278452e-01,\n",
       "         -2.32485637e-01, -6.63026810e-01],\n",
       "        [-1.54889494e-01, -2.14330956e-01, -6.96583912e-02,\n",
       "         -9.89800692e-02,  3.22032541e-01,  1.04813520e-02,\n",
       "         -2.31876418e-01,  1.10546544e-01, -3.11309010e-01,\n",
       "          1.69211060e-01,  3.29328030e-01, -2.38911748e-01,\n",
       "          2.19226226e-01, -1.61344051e-01, -3.33915591e-01,\n",
       "         -2.12924823e-01, -2.43073683e-02, -7.46480227e-02,\n",
       "          3.37322980e-01,  7.92630911e-02,  1.50093883e-01,\n",
       "          1.50760502e-01,  3.70295644e-02,  2.99206346e-01,\n",
       "          1.12260610e-01, -6.57246932e-02, -1.67102307e-01,\n",
       "          1.25462621e-01,  1.81754500e-01,  4.23242748e-02,\n",
       "          4.62345779e-02,  2.92643517e-01],\n",
       "        [-2.92708606e-01, -2.15509564e-01,  1.67145818e-01,\n",
       "         -2.00913221e-01,  4.51862693e-01, -2.86021709e-01,\n",
       "         -3.25192928e-01,  5.90136230e-01,  8.79146680e-02,\n",
       "         -2.19774768e-01,  1.18134812e-01, -3.40046763e-01,\n",
       "          3.51387918e-01,  7.76079744e-02, -1.82204142e-01,\n",
       "          1.35101214e-01, -3.27872545e-01, -1.04031861e-01,\n",
       "          1.73764363e-01,  3.16707850e-01,  3.86480838e-01,\n",
       "          1.64465904e-02,  3.77202481e-01, -1.01744287e-01,\n",
       "         -2.95724183e-01, -2.39916623e-01, -3.29338491e-01,\n",
       "          3.46804634e-02,  4.98494446e-01, -2.48275906e-01,\n",
       "         -2.39920974e-01,  3.47991407e-01]], dtype=float32),\n",
       " array([ 0.125664  ,  0.14860526, -0.01094316,  0.        , -0.02452203,\n",
       "         0.10043526,  0.        , -0.0125536 ,  0.1025981 ,  0.13384226,\n",
       "         0.03867216, -0.0037655 , -0.04067821,  0.00890138, -0.03754447,\n",
       "        -0.01048651,  0.14698692, -0.00051261,  0.07313428, -0.00639478,\n",
       "        -0.01498237,  0.        , -0.03419633,  0.08456519,  0.        ,\n",
       "         0.13466936,  0.        ,  0.14265183,  0.01893993, -0.00152371,\n",
       "        -0.00051303,  0.02333261], dtype=float32),\n",
       " array([[ 0.6297847 , -0.21219882],\n",
       "        [ 0.4561737 , -0.49756712],\n",
       "        [-0.64256483,  0.62047064],\n",
       "        [-0.11511809, -0.06393173],\n",
       "        [-0.55187255,  0.2093984 ],\n",
       "        [ 0.5810119 , -0.6701608 ],\n",
       "        [ 0.37593856, -0.06085703],\n",
       "        [-0.63227314,  0.15571262],\n",
       "        [ 0.17435405, -0.5581464 ],\n",
       "        [ 0.6902368 , -0.03354666],\n",
       "        [ 0.21242927, -0.52522945],\n",
       "        [-0.14280164,  0.40567422],\n",
       "        [-0.3450431 ,  0.26498234],\n",
       "        [-0.00501967, -0.16101003],\n",
       "        [-0.19618753,  0.22940853],\n",
       "        [ 0.32151437, -0.39501342],\n",
       "        [ 0.29649654, -0.62501365],\n",
       "        [ 0.15491268,  0.2189047 ],\n",
       "        [ 0.24457058, -0.45322973],\n",
       "        [-0.2102852 ,  0.41277638],\n",
       "        [-0.20246692,  0.38450906],\n",
       "        [ 0.20404616,  0.02839759],\n",
       "        [-0.27404907,  0.38240406],\n",
       "        [ 0.4167517 , -0.59691715],\n",
       "        [-0.10476029, -0.35285607],\n",
       "        [ 0.24972469, -0.7507934 ],\n",
       "        [ 0.40767637, -0.30596134],\n",
       "        [ 0.35729912, -0.54499424],\n",
       "        [-0.4737485 ,  0.29078758],\n",
       "        [-0.08018526, -0.01558404],\n",
       "        [-0.20355807,  0.1765115 ],\n",
       "        [-0.27545604,  0.5080676 ]], dtype=float32),\n",
       " array([ 0.01869184, -0.01869184], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x1c262ca470>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. model.to_json()\n",
    "\n",
    "#### This is only saving the architecture of the model. No weights or training configuration will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as JSOW\n",
    "json_string = model.to_json()\n",
    "\n",
    "# save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"theano\"}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model reconstruction from JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you only want the weights, you can save it as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.hS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('my_model_weights.hS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
